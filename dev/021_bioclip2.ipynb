{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1f2e45-3b4c-45e6-a11a-9bb0f86afdb1",
   "metadata": {},
   "source": [
    "# Try to use BioCLIP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36507899-c03c-4665-9700-2e6dd74691bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from open_clip import create_model, get_tokenizer\n",
    "import polars as pl\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "import json\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import collections\n",
    "import heapq\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import asyncio, aiohttp\n",
    "import pandas as pd\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:imageomics/bioclip-2')\n",
    "# tokenizer = open_clip.get_tokenizer('hf-hub:imageomics/bioclip-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48e112-7736-435e-b23c-7e3d561e4e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = \"hf-hub:imageomics/bioclip-2\"\n",
    "tokenizer_str = \"ViT-L-14\"\n",
    "HF_DATA_STR = \"imageomics/TreeOfLife-200M\"\n",
    "\n",
    "min_prob = 1e-9\n",
    "k = 5\n",
    "\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "preprocess_img = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize((224, 224), antialias=True),\n",
    "        transforms.Normalize(\n",
    "            mean=(0.48145466, 0.4578275, 0.40821073),\n",
    "            std=(0.26862954, 0.26130258, 0.27577711),\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ranks = (\"Kingdom\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\", \"Species\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be6e25c-4339-4586-b609-4a00be80368e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(model_str, output_dict=True, require_pretrained=True)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7898d961-9b76-4b11-b852-1795316c43da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e3b825-7525-4a5c-b74e-f9ab73155152",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(tokenizer_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6818c7c5-5a1b-47e2-8af5-b466b9c42c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_emb = torch.from_numpy(np.load(hf_hub_download(\n",
    "        repo_id=HF_DATA_STR,\n",
    "        filename=\"embeddings/txt_emb_species.npy\",\n",
    "        repo_type=\"dataset\",\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f1f81-2b6e-4a9b-9409-a92c72b3d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(hf_hub_download(\n",
    "        repo_id=HF_DATA_STR,\n",
    "        filename=\"embeddings/txt_emb_species.json\",\n",
    "        repo_type=\"dataset\",\n",
    "    )) as fd:\n",
    "        txt_names = json.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986c98af-6d1b-4e90-aef0-fbe5c14d0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_sample(df, pred_taxon, rank):\n",
    "#     '''\n",
    "#     Function to retrieve a sample image of the predicted taxon and GBIF or EOL page link for more info.\n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     df : DataFrame\n",
    "#         DataFrame with all sample images listed and their filepaths (in \"file_path\" column).\n",
    "#     pred_taxon : str\n",
    "#         Predicted taxon of the uploaded image.\n",
    "#     rank : int\n",
    "#         Index of rank in RANKS chosen for prediction.\n",
    "#     Returns:\n",
    "#     --------\n",
    "#     img : PIL.Image\n",
    "#         Sample image of predicted taxon for display.\n",
    "#     ref_page : str\n",
    "#         URL to GBIF or EOL page for the taxon (may be a lower rank, e.g., species sample).\n",
    "#     '''\n",
    "#     logger.info(f\"Getting sample for taxon: {pred_taxon} at rank: {rank}\")\n",
    "#     try:\n",
    "#         filepath, gbif_taxon_id, eol_page_id, full_name, is_exact = get_sample_data(df, pred_taxon, rank)\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error retrieving sample data: {e}\")\n",
    "#         return None, f\"We encountered the following error trying to retrieve a sample image: {e}.\"\n",
    "#     if filepath is None:\n",
    "#         logger.warning(f\"No sample image found for taxon: {pred_taxon}\")\n",
    "#         return None, f\"Sorry, our GBIF and EOL images do not include {pred_taxon}.\"\n",
    "\n",
    "#     # Get sample image of selected individual\n",
    "#     try:\n",
    "#         img_src = s3_client.generate_presigned_url('get_object',\n",
    "#                                                    Params={'Bucket': 'treeoflife-200m-sample-images',\n",
    "#                                                            'Key': filepath}\n",
    "#                                                    )\n",
    "#         img_resp = requests.get(img_src)\n",
    "#         img = Image.open(io.BytesIO(img_resp.content))\n",
    "#         if gbif_taxon_id:\n",
    "#             gbif_url = GBIF_URL + gbif_taxon_id\n",
    "#             if eol_page_id:\n",
    "#                 eol_url = EOL_URL + eol_page_id\n",
    "#                 if is_exact:\n",
    "#                     ref_page = f\"<p>Check out the <a href={eol_url} target='_blank'>EOL</a> or <a href={gbif_url} target='_blank'>GBIF</a> entry for {pred_taxon} to learn more.</p>\"\n",
    "#                 else:\n",
    "#                     ref_page = f\"<p>Check out an example entry within {pred_taxon} to learn more: {full_name} at <a href={eol_url} target='_blank'>EOL</a> or <a href={gbif_url} target='_blank'>GBIF</a>.</p>\"\n",
    "#             else:\n",
    "#                 if is_exact:\n",
    "#                     ref_page = f\"<p>Check out the <a href={gbif_url} target='_blank'>GBIF</a> entry for {pred_taxon} to learn more.</p>\"\n",
    "#                 else:\n",
    "#                     ref_page = f\"<p>Check out an example GBIF entry within {pred_taxon} to learn more: <a href={gbif_url} target='_blank'>{full_name}</a>.</p>\"\n",
    "#         else:\n",
    "#             eol_url = EOL_URL + eol_page_id\n",
    "#             if is_exact:\n",
    "#                     ref_page = f\"<p>Check out the <a href={eol_url} target='_blank'>EOL</a> entry for {pred_taxon} to learn more.</p>\"\n",
    "#             else:\n",
    "#                 ref_page = f\"<p>Check out an example EOL entry within {pred_taxon} to learn more: <a href={eol_url} target='_blank'>{full_name}</a>.</p>\"\n",
    "#         logger.info(f\"Successfully retrieved sample image and page for {pred_taxon}\")\n",
    "#         return img, ref_page\n",
    "#     except Exception as e:\n",
    "#         logger.error(f\"Error retrieving sample image: {e}\")\n",
    "#         return None, f\"We encountered the following error trying to retrieve a sample image: {e}.\"\n",
    "\n",
    "def format_name(taxon, common):\n",
    "    taxon = \" \".join(taxon)\n",
    "    if not common:\n",
    "        return taxon\n",
    "    return f\"{taxon} ({common})\"\n",
    "\n",
    "@torch.no_grad()\n",
    "def open_domain_classification(img, rank: int, return_all=False):\n",
    "    \"\"\"\n",
    "    Predicts from the entire tree of life.\n",
    "    If targeting a higher rank than species, then this function predicts among all\n",
    "    species, then sums up species-level probabilities for the given rank.\n",
    "    \"\"\"\n",
    "\n",
    "    # logger.info(f\"Starting open domain classification for rank: {rank}\")\n",
    "    # print(f\"Starting open domain classification for rank: {rank}\")\n",
    "    img = preprocess_img(img).to(device)\n",
    "    img_features = model.encode_image(img.unsqueeze(0))\n",
    "    img_features = F.normalize(img_features, dim=-1)\n",
    "\n",
    "    logits = (model.logit_scale.exp() * img_features @ txt_emb.to(device)).squeeze()\n",
    "    probs = F.softmax(logits, dim=0)\n",
    "\n",
    "    if rank + 1 == len(ranks):\n",
    "        topk = probs.topk(k)\n",
    "        prediction_dict = {\n",
    "            format_name(*txt_names[i]): prob for i, prob in zip(topk.indices, topk.values)\n",
    "        }\n",
    "        # logger.info(f\"Top K predictions: {prediction_dict}\")\n",
    "        # print(f\"Top K predictions: {prediction_dict}\")\n",
    "        top_prediction_name = format_name(*txt_names[topk.indices[0]]).split(\"(\")[0]\n",
    "        # logger.info(f\"Top prediction name: {top_prediction_name}\")\n",
    "        # print(f\"Top prediction name: {top_prediction_name}\")\n",
    "        # sample_img, taxon_url = get_sample(metadata_df, top_prediction_name, rank)\n",
    "        if return_all:\n",
    "            return prediction_dict, sample_img, taxon_url\n",
    "        return prediction_dict\n",
    "\n",
    "    output = collections.defaultdict(float)\n",
    "    for i in torch.nonzero(probs > min_prob).squeeze():\n",
    "        output[\" \".join(txt_names[i][0][: rank + 1])] += probs[i]\n",
    "\n",
    "    topk_names = heapq.nlargest(k, output, key=output.get)\n",
    "    prediction_dict = {name: output[name] for name in topk_names}\n",
    "    # logger.info(f\"Top K names for output: {topk_names}\")\n",
    "    # logger.info(f\"Prediction dictionary: {prediction_dict}\")\n",
    "    # print(f\"Top K names for output: {topk_names}\")\n",
    "    # print(f\"Prediction dictionary: {prediction_dict}\")\n",
    "\n",
    "    top_prediction_name = topk_names[0]\n",
    "    # logger.info(f\"Top prediction name: {top_prediction_name}\")\n",
    "    # print(f\"Top prediction name: {top_prediction_name}\")\n",
    "    # sample_img, taxon_url = get_sample(metadata_df, top_prediction_name, rank)\n",
    "    # logger.info(f\"Sample image and taxon URL: {sample_img}, {taxon_url}\")\n",
    "    # print(f\"Sample image and taxon URL: {sample_img}, {taxon_url}\")\n",
    "\n",
    "    if return_all:\n",
    "        return prediction_dict, sample_img, taxon_url\n",
    "    return prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa73e8-6faf-4500-83e4-836fb5c5f1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pth = Path(\"/home/george/codes/lepinet/data/flemming_ucloud/images/1732063/0e343351-e995-4255-9868-61ef7dc06039.jpg\")\n",
    "img_pth = Path(\"/home/george/codes/lepinet/data/flemming_ucloud/images/1811896/ad530cad-ed7a-4bf8-9572-1e516d57e6bb.jpg\")\n",
    "img = Image.open(img_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef5596-1054-4efc-8c80-e02ceb6367fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = open_domain_classification(img, len(ranks)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3844bd-9729-44ce-8399-8ec81ee1b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333c807a-e55c-4731-9b02-f3b803f64791",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ = [(k,v) for k,v in pred.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a408323-8b6e-4c19-987c-a681dc6e1c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(pred_[0][0].split(' ')[5:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e40361-87b4-41b0-9cdb-04497bcfd7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = Path(\"/home/george/codes/lepinet/data/flemming_ucloud/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c82661-eca7-4a3e-ad56-560842ba2b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filenames = list(img_dir.glob('*/*.jpg'))\n",
    "img_filenames[:10], len(img_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee9129-e7cf-4890-9375-cf80684ef137",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "img_size = 224\n",
    "\n",
    "preds = []\n",
    "\n",
    "# img_filenames=img_filenames[:10]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(0,len(img_filenames),batch_size)):\n",
    "        bs = min(batch_size, len(img_filenames)-i)\n",
    "        batch = torch.FloatTensor(bs, 3, img_size, img_size) \n",
    "        for j in range(bs):\n",
    "            img_pth = img_filenames[i+j]\n",
    "            img = cv2.imread(img_pth)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = preprocess_img(img)\n",
    "            batch[j] = img\n",
    "    \n",
    "        img_features = model.encode_image(batch.to(device))\n",
    "        img_features = F.normalize(img_features, dim=-1)\n",
    "        \n",
    "        # logits = (model.logit_scale.exp() * img_features @ txt_emb).squeeze()\n",
    "        logits = (model.logit_scale.exp() * img_features @ txt_emb.to(device))\n",
    "        # probs = F.softmax(logits, dim=0)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        # topk = probs.topk(k)\n",
    "        topk = probs.topk(k, dim=1)\n",
    "\n",
    "        # prediction_dict = {\n",
    "        #     format_name(*txt_names[i]): prob for i, prob in zip(topk.indices, topk.values)\n",
    "        # }\n",
    "        # pred = open_domain_classification(img, rank=len(ranks)-1)\n",
    "        # pred_ = [(k,v) for k,v in pred.items()]\n",
    "        # preds += [(' '.join(pred_[0][0].split(' ')[5:7]), float(pred_[0][1]))]\n",
    "        prediction_dict = [{\n",
    "            format_name(*txt_names[k]): prob for k, prob in zip(indices, values)\n",
    "        } for indices, values in zip(topk.indices, topk.values) ]\n",
    "    \n",
    "        prediction_list = [[(k,v) for k,v in pred.items()] for pred in prediction_dict]\n",
    "        preds += [(pred_[0][0].split(' ')[4], pred_[0][0].split(' ')[5], ' '.join(pred_[0][0].split(' ')[5:7]), float(pred_[0][1])) for pred_ in prediction_list]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2971b5-3214-48d6-94f6-9c888ac6aa1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c279a1-bb24-49e0-8d7e-8cbc6463951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_key(session, scientificName=None, usageKey=None, rank='SPECIES', order='Lepidoptera', family=None, genus=None):\n",
    "    url = \"https://api.gbif.org/v1/species/match?\"\n",
    "    # assert usageKey is not None or scientificName is not None, \"One of scientificName or usageKey must be defined.\"\n",
    "\n",
    "    if usageKey is not None:\n",
    "        url += f\"usageKey={usageKey}&\"\n",
    "    if scientificName is not None:\n",
    "        if scientificName=='Tethea or': return 5142971 # bug fix\n",
    "        url += f\"scientificName={scientificName}&\"\n",
    "    if rank is not None:\n",
    "        url += f\"rank={rank}&\"\n",
    "    if order is not None:\n",
    "        url += f\"order={order}\"\n",
    "    if family is not None:\n",
    "        url += f\"family={family}\"\n",
    "    if genus is not None:\n",
    "        url += f\"genus={genus}\"\n",
    "\n",
    "    async with session.get(url) as response:\n",
    "        r = await response.json()\n",
    "        # return r if not 'canonicalName' in r.keys() else r['canonicalName']\n",
    "        if rank in [None, 'SPECIES']:\n",
    "            return r if not 'speciesKey' in r.keys() else r['speciesKey']\n",
    "        elif rank == 'GENUS':\n",
    "            return r if not 'genusKey' in r.keys() else r['genusKey']\n",
    "        elif rank == 'FAMILY':\n",
    "            return r if not 'familyKey' in r.keys() else r['familyKey']\n",
    "            \n",
    "async def get_all_keys(vocab):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [get_key(session, scientificName=k, rank=None) for k in vocab]\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "async def get_all_family(vocab):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [get_key(session, scientificName=k, rank='FAMILY') for k in vocab]\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "async def get_all_genus(vocab):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [get_key(session, scientificName=k, rank='GENUS') for k in vocab]\n",
    "        return await asyncio.gather(*tasks)\n",
    "\n",
    "async def get_parents(session, usageKey):\n",
    "    url = \"https://api.gbif.org/v1/species/{}/parents\"\n",
    "    if usageKey is not None:\n",
    "        url = url.format(usageKey)\n",
    "        \n",
    "    async with session.get(url) as response:\n",
    "        r = await response.json()\n",
    "        return r\n",
    "\n",
    "async def get_all_parents(vocab):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [get_parents(session, usageKey=k) for k in vocab]\n",
    "        return await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3901bc-50ef-4483-aef0-6f08911378b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = ('FAMILY','GENUS','SPECIES')\n",
    "species = []\n",
    "genera = []\n",
    "families = []\n",
    "cnfs = []\n",
    "for i, (f,g,s,v) in enumerate(preds):\n",
    "    species.append(s)\n",
    "    genera.append(g)\n",
    "    families.append(f)\n",
    "    cnfs.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e09b75b-7581-43ac-b247-60375483c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnfs[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e103c135-1507-443a-a49a-eff3f9ad7405",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_keys = dict(\n",
    "species_keys = asyncio.run(get_all_keys(species)),\n",
    "genera_keys = asyncio.run(get_all_genus(genera)),\n",
    "family_keys = asyncio.run(get_all_family(families)),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb936d2-2fcc-4f5d-b395-fef83e4440f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [f.parent.name for i, f in enumerate(img_filenames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90370b60-2a42-448e-b653-f917eda823c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parents=asyncio.run(get_all_parents(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6166509e-c010-4dc5-bb54-1d9c30f36f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_all = []\n",
    "for i,p in enumerate(parents):\n",
    "    labels_all += [int(labels[i]), p[-1]['genusKey'], p[-1]['familyKey']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bc1649-71c0-4c58-8ca7-d826493f69c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds_keys['species_keys']),len("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc138a9b-8bf8-4451-baaf-260bda2d914a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "instance_id=[]\n",
    "filename=[]\n",
    "level=[]\n",
    "label=[]\n",
    "prediction=[]\n",
    "confidence=[]\n",
    "threshold=[] \n",
    "\n",
    "for i, f in enumerate(img_filenames):\n",
    "    for j, l in enumerate(['species_keys','genera_keys','family_keys']):\n",
    "        instance_id += [i]\n",
    "        filename += [f]\n",
    "        level += [j]\n",
    "        label += [labels_all[i*3+j]]\n",
    "        prediction += [preds_keys[l][i]]\n",
    "        confidence += [float(cnfs[i])]\n",
    "        threshold += [0.0]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'instance_id':instance_id,\n",
    "    'filename':filename,\n",
    "    'level':level,\n",
    "    'label':label,\n",
    "    'prediction':prediction,\n",
    "    'confidence':confidence,\n",
    "    'threshold':threshold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb78983-4408-4e34-999c-61936219fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bioclip_pth = Path(\"/home/george/codes/lepinet/data/flemming_ucloud/bioclip2/bioclip2.csv\")\n",
    "df.to_csv(bioclip_pth, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c9eaaa-a308-49bd-8a6e-4d663b2ea313",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7738ebd2-c5fd-432a-84b7-45d88b349d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('hello')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
