{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbcad29-3871-4495-aaea-a4934596ad7a",
   "metadata": {},
   "source": [
    "# Integrate Asger's heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735b81a0-8d8a-49f2-8eca-8abb27b90e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "import torchvision\n",
    "\n",
    "# from mini_trainer.classifier import Classifier\n",
    "from mini_trainer.hierarchical.integration import sparse_masks_from_labels, HierarchicalBuilder\n",
    "from mini_trainer.hierarchical.model import HierarchicalClassifier\n",
    "from mini_trainer.hierarchical.loss import MultiLevelWeightedCrossEntropyLoss, MultiLevelLoss\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import yaml\n",
    "\n",
    "from fastai.learner import Learner\n",
    "from fastai.vision.all import (\n",
    "    DataBlock,\n",
    "    ImageBlock,\n",
    "    MultiCategoryBlock,\n",
    "    CategoryBlock,\n",
    "    ColSplitter,\n",
    "    ColReader,\n",
    "    Pipeline,\n",
    "    Resize,\n",
    "    aug_transforms,\n",
    "    vision_learner,\n",
    "    # partial,\n",
    "    # F1ScoreMulti,\n",
    "    # accuracy_multi,\n",
    "    # ShowGraphCallback,\n",
    "    # CSVLogger,\n",
    "    # EarlyStoppingCallback,\n",
    "    # ImageDataLoaders,\n",
    "    # SaveModelCallback,\n",
    "    DisplayedTransform,\n",
    ")\n",
    "# from fastai.transform import Transform\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174636f3-32ee-46cf-8ab6-e11e4f6c36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hier_path = Path(\"/home/george/codes/lepinet/data/global_lepi/hierarchy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098818b9-2306-4175-b05b-12481fd7f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hier = pd.read_csv(hier_path)\n",
    "labels = {str(r['speciesKey']):r.values.astype(str).tolist() for i,r in hier.iterrows()}\n",
    "cls2idx = {str(i):{str(e):j for j,e in enumerate(s.unique())} for i,(n,s) in enumerate(hier.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d68794c-3c92-433c-b97d-5c2603ae2496",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_masks=sparse_masks_from_labels(labels, cls2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d39b03b-a696-4e1f-afdc-e9c5752edce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model_builder_kwargs ={\n",
    "            \"model_type\" : \"efficientnet_v2_s\",\n",
    "            \"weights\" : None,\n",
    "            \"hidden\" : 512,\n",
    "            \"droprate\" : 0.1,\n",
    "            \"normalized\" : True,\n",
    "            \"sparse_masks\" : sparse_masks,\n",
    "            \"num_classes\" : len(cls2idx['0']),\n",
    "        }\n",
    "model, model_preprocessor = HierarchicalClassifier.build(**model_builder_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3d6053",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9211bc21-aeb3-4e9f-a3e1-2c985324a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "class SumMultiLevelWeightedCrossEntropyLoss(torch.nn.modules.loss._Loss):\n",
    "    def __init__(\n",
    "            self, \n",
    "            weights : list[float | int] | torch.Tensor,\n",
    "            device : torch._prims_common.DeviceLikeType, \n",
    "            dtype : torch.types._dtype, \n",
    "            class_weights : list[torch.Tensor] | None=None,\n",
    "            label_smoothing : float = 0.0\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.weights = torch.tensor(weights).to(device=device, dtype=dtype)\n",
    "        self.n_levels = len(weights)\n",
    "        self.label_smoothing = [1 - (1 - label_smoothing)**(1/(i+1)) for i in range(self.n_levels)]\n",
    "        \n",
    "        self._loss_fns = [\n",
    "            nn.CrossEntropyLoss(\n",
    "                # weight=None, #self.class_weights[i], \n",
    "                # reduction=\"none\", \n",
    "                label_smoothing=label_smoothing\n",
    "            ) for _ in range(self.n_levels)\n",
    "        ]\n",
    "\n",
    "    def __call__(\n",
    "            self, \n",
    "            preds : torch.Tensor, \n",
    "            *targets\n",
    "        ) -> \"MultiLevelLoss\":\n",
    "        return sum(list(MultiLevelLoss(\n",
    "            [\n",
    "                self._loss_fns[i](preds[i], targets[i])\n",
    "                for i in range(self.n_levels)\n",
    "            ], \n",
    "             self.weights\n",
    "        )))\n",
    "loss = SumMultiLevelWeightedCrossEntropyLoss(weights=[1.0,1.0,1,0], device='cpu', dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5af91fd-1258-4868-8750-6611a1b6f4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = Path(\"/home/george/codes/lepinet/configs/20251106_1_test_ece.yaml\")\n",
    "with open(config_path) as f:\n",
    "    config=yaml.safe_load(f)\n",
    "# gen_dls = getattr(importlib.import_module('011_lepi_large_prod_v2'), 'gen_dls')\n",
    "# dls,hierarchy=gen_dls(**config['train'])\n",
    "# model_arch = getattr(importlib.import_module('fastai.vision.all'), config['train']['model_arch_name'])\n",
    "# learn = vision_learner(dls, model_arch)\n",
    "# learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454bffed-ccac-45d8-862c-05b5ddd47034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_path = Path(\"/home/george/codes/lepinet/data/global_lepi/0032836-250426092105405_processing_metadata_postprocessed_quality_filtered.lepinet.parquet\")\n",
    "df = pd.read_parquet(df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fe78a-39c9-4123-9e6a-9244e909d961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c47596a-f064-4b17-bbd7-3b6eefba0179",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,r=next(iter(df.iterrows()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ecfbc-a53d-428a-868d-388c03bf7d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "r['speciesKey'], r['genusKey'], r['familyKey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bbfe1-d559-410e-9bde-d5cb78ff8637",
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_img_size = 460\n",
    "img_size = 256\n",
    "batch_size = 64\n",
    "\n",
    "img_dir = Path(\"/home/george/codes/lepinet/data/global_lepi/images\")\n",
    "vocab=[]\n",
    "for c in hier.columns: vocab.extend(hier[c].unique().astype(str).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee7164d-efeb-410e-afbe-1a28752cd8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "datablock = DataBlock(\n",
    "        blocks=(ImageBlock, MultiCategoryBlock(vocab=vocab)),\n",
    "        splitter=ColSplitter(),\n",
    "        get_x=ColReader(0, pref=img_dir),\n",
    "        get_y=ColReader(1, label_delim=' '),\n",
    "        item_tfms=Resize(aug_img_size),\n",
    "        batch_tfms=aug_transforms(size=img_size)\n",
    "    )\n",
    "dls = datablock.dataloaders(df, bs=batch_size)\n",
    "end = time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2b24e-cbb9-4528-ab00-d34f032f7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['speciesKey','genusKey','familyKey']] = df['hierarchy_labels'].str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d1c43-6fbc-455c-b732-ed716b6cd724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d750f01a-42a4-4aca-8d05-51e46f710886",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_3 = df['speciesKey'].unique().tolist()\n",
    "vocab_4 = df['genusKey'].unique().tolist()\n",
    "vocab_5 = df['familyKey'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417fb5e2-15e7-4fe8-b47f-903febeeb410",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock(vocab=vocab_3), CategoryBlock(vocab=vocab_4), CategoryBlock(vocab=vocab_5)),\n",
    "    n_inp=1,\n",
    "    splitter=ColSplitter(),\n",
    "    get_x=ColReader(0, pref=img_dir),\n",
    "    get_y=[ColReader(3), ColReader(4), ColReader(5)],\n",
    "    item_tfms=[Resize(aug_img_size), model_preprocessor],\n",
    "    batch_tfms=aug_transforms(size=img_size)\n",
    ")\n",
    "dls = datablock.dataloaders(df, bs=4)\n",
    "end = time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee2bc7-05e2-41a5-be0e-033ba2fae5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=dls.train.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c63f11c-ce12-4bb4-9bf9-777f050a0652",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[-1].tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7644a4-1efc-4d13-87b2-37109e5afbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31251c54-f250-4421-b95e-0096438a7bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[1].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6298fda-c834-4f58-873d-7697936906cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out=model(model_preprocessor(b[0].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c506807-2d70-42c7-a110-74095f084754",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d29ed1-eb4c-4075-953a-7d4737cd3e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d12c7-69fd-4423-abce-2efe4a1f3d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "b[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f5476a-2252-4ddb-816c-ec71264a5dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in out]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d055b73-dcb7-46f8-a2c3-07f9466ccb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "[type(i) for i in list(b[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61128e68-1b7e-4ace-a37a-371dd4e46fbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss(out,list(b[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cead2bcc-0652-4f34-a935-18e7ea6aaa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(SumMultiLevelWeightedCrossEntropyLoss(weights=[1.0,1.0,1,0], device='cpu', dtype=torch.float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b363da1-119c-4668-b854-7cbf328abb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(\n",
    "    dls,\n",
    "    model,\n",
    "    loss_func=SumMultiLevelWeightedCrossEntropyLoss(weights=[1.0,0.0,0.0], device='cuda', dtype=torch.float),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5711e6-5a7e-45f2-bbdb-27d800b23ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec7ca5f-3835-4109-be64-2ffb996f46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e3f15-fa1d-46b7-bedc-006c641107d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classif",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
