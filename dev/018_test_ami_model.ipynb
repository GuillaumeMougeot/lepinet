{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537a3a9c-54fa-42c9-815c-b741935f4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms\n",
    "import datetime, time\n",
    "import json\n",
    "from typing import Union\n",
    "import pathlib\n",
    "import urllib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "FilePath = Union[pathlib.Path, str]\n",
    "\n",
    "def slugify(s):\n",
    "    # Quick method to make an acceptable attribute name or url part from a title\n",
    "    # install python-slugify for handling unicode chars, numbers at the beginning, etc.\n",
    "    separator = \"_\"\n",
    "    acceptable_chars = list(string.ascii_letters) + list(string.digits) + [separator]\n",
    "    return (\n",
    "        \"\".join(\n",
    "            [\n",
    "                chr\n",
    "                for chr in s.replace(\" \", separator).lower()\n",
    "                if chr in acceptable_chars\n",
    "            ]\n",
    "        )\n",
    "        .strip(separator)\n",
    "        .replace(separator * 2, separator)\n",
    "    )\n",
    "\n",
    "def get_or_download_file(\n",
    "    path, destination_dir=None, prefix=None, suffix=None\n",
    ") -> pathlib.Path:\n",
    "    \"\"\"\n",
    "    >>> filename, headers = get_weights(\"https://drive.google.com/file/d/1KdQc56WtnMWX9PUapy6cS0CdjC8VSdVe/view?usp=sharing\")\n",
    "\n",
    "    \"\"\"\n",
    "    if not path:\n",
    "        raise Exception(\"Specify a URL or path to fetch file from.\")\n",
    "\n",
    "    # If path is a local path instead of a URL then urlretrieve will just return that path\n",
    "    destination_dir = destination_dir or os.environ.get(\"LOCAL_WEIGHTS_PATH\")\n",
    "    fname = path.rsplit(\"/\", 1)[-1]\n",
    "    if destination_dir:\n",
    "        destination_dir = pathlib.Path(destination_dir)\n",
    "        if prefix:\n",
    "            destination_dir = destination_dir / prefix\n",
    "        if not destination_dir.exists():\n",
    "            logger.info(f\"Creating local directory {str(destination_dir)}\")\n",
    "            destination_dir.mkdir(parents=True, exist_ok=True)\n",
    "        local_filepath = pathlib.Path(destination_dir) / fname\n",
    "        if suffix:\n",
    "            local_filepath = local_filepath.with_suffix(suffix)\n",
    "    else:\n",
    "        raise Exception(\n",
    "            \"No destination directory specified by LOCAL_WEIGHTS_PATH or app settings.\"\n",
    "        )\n",
    "\n",
    "    if local_filepath and local_filepath.exists():\n",
    "        logger.info(f\"Using existing {local_filepath}\")\n",
    "        return local_filepath\n",
    "\n",
    "    else:\n",
    "        logger.info(f\"Downloading {path} to {local_filepath}\")\n",
    "        resulting_filepath, headers = urllib.request.urlretrieve(\n",
    "            url=path, filename=local_filepath\n",
    "        )\n",
    "        resulting_filepath = pathlib.Path(resulting_filepath)\n",
    "        logger.info(f\"Downloaded to {resulting_filepath}\")\n",
    "        return resulting_filepath\n",
    "\n",
    "def get_device(device_str=None) -> torch.device:\n",
    "    \"\"\"\n",
    "    Select CUDA if available.\n",
    "\n",
    "    @TODO add macOS Metal?\n",
    "    @TODO check Kivy settings to see if user forced use of CPU\n",
    "    \"\"\"\n",
    "    if not device_str:\n",
    "        device_str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    device = torch.device(device_str)\n",
    "    logger.info(f\"Using device '{device}' for inference\")\n",
    "    return device\n",
    "\n",
    "def synchronize_clocks():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "class StopWatch:\n",
    "    \"\"\"\n",
    "    Measure inference time with GPU support.\n",
    "\n",
    "    >>> with stopwatch() as t:\n",
    "    >>>     sleep(5)\n",
    "    >>> int(t.duration)\n",
    "    >>> 5\n",
    "    \"\"\"\n",
    "\n",
    "    def __enter__(self):\n",
    "        synchronize_clocks()\n",
    "        # self.start = time.perf_counter()\n",
    "        self.start = time.time()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        synchronize_clocks()\n",
    "        # self.end = time.perf_counter()\n",
    "        self.end = time.time()\n",
    "        self.duration = self.end - self.start\n",
    "\n",
    "    def __repr__(self):\n",
    "        start = datetime.datetime.fromtimestamp(self.start).strftime(\"%H:%M:%S\")\n",
    "        end = datetime.datetime.fromtimestamp(self.end).strftime(\"%H:%M:%S\")\n",
    "        seconds = int(round(self.duration, 1))\n",
    "        return f\"Started: {start}, Ended: {end}, Duration: {seconds} seconds\"\n",
    "\n",
    "\n",
    "#KBE??? \n",
    "class Logger():\n",
    "    \n",
    "    def info(self, text):\n",
    "        print(\"Info:\", text)\n",
    "    \n",
    "    def debug(self, text):\n",
    "        return\n",
    "        # print(\"Debug:\", text)\n",
    "        \n",
    "logger = Logger()\n",
    "#KBE??? \n",
    "\n",
    "class BatchEmptyException(Exception):\n",
    "    pass\n",
    "\n",
    "\n",
    "def zero_okay_collate(batch):\n",
    "    \"\"\"\n",
    "    If the queue is cleared or shortened before the original batch count is complete\n",
    "    then the dataloader will crash. This catches the empty batch more gracefully.\n",
    "\n",
    "    @TODO switch to streaming IterableDataset type.\n",
    "    \"\"\"\n",
    "    if any(not item for item in batch):\n",
    "        logger.debug(f\"There's a None in the batch of len {len(batch)}\")\n",
    "        return None\n",
    "    else:\n",
    "        return torch.utils.data.default_collate(batch)\n",
    "\n",
    "\n",
    "imagenet_normalization = torchvision.transforms.Normalize(\n",
    "    # \"torch preprocessing\"\n",
    "    mean=[0.485, 0.456, 0.406],  # RGB\n",
    "    std=[0.229, 0.224, 0.225],  # RGB\n",
    ")\n",
    "\n",
    "tensorflow_normalization = torchvision.transforms.Normalize(\n",
    "    # -1 to 1\n",
    "    mean=[0.5, 0.5, 0.5],  # RGB\n",
    "    std=[0.5, 0.5, 0.5],  # RGB\n",
    ")\n",
    "\n",
    "generic_normalization = torchvision.transforms.Normalize(\n",
    "    # 0 to 1\n",
    "    mean=[0.5, 0.5, 0.5],  # RGB\n",
    "    std=[0.5, 0.5, 0.5],  # RGB\n",
    ")\n",
    "\n",
    "\n",
    "class InferenceBaseClass:\n",
    "    \"\"\"\n",
    "    Base class for all batch-inference models.\n",
    "\n",
    "    This outlines a common interface for all classifiers and object detectors.\n",
    "    Generic methods like `get_weights_from_url` are defined here, but\n",
    "    methods that return NotImplementedError must be overridden in a subclass\n",
    "    that is specific to each inference model.\n",
    "\n",
    "    See examples in `classification.py` and `localization.py`\n",
    "    \"\"\"\n",
    "\n",
    "    #KBE??? db_path: Union[str, sqlalchemy.engine.URL]\n",
    "    image_base_path: FilePath\n",
    "    name = \"Unknown Inference Model\"\n",
    "    description = str()\n",
    "    model_type = None\n",
    "    device = None\n",
    "    weights_path = None\n",
    "    weights = None\n",
    "    labels_path = None\n",
    "    category_map = {}\n",
    "    num_classes: Union[int, None] = None  # Will use len(category_map) if None\n",
    "    lookup_gbif_names: bool = False\n",
    "    model: torch.nn.Module\n",
    "    normalization = tensorflow_normalization\n",
    "    transforms: torchvision.transforms.Compose\n",
    "    batch_size = 4\n",
    "    num_workers = 1\n",
    "    user_data_path = None\n",
    "    type = \"unknown\"\n",
    "    stage = 0\n",
    "    single = True\n",
    "    #KBE??? queue: QueueManager\n",
    "    dataset: torch.utils.data.Dataset\n",
    "    dataloader: torch.utils.data.DataLoader\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        #KBE??? db_path: Union[str, sqlalchemy.engine.URL],\n",
    "        user_data_path: FilePath,\n",
    "        image_base_path: FilePath,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        #KBE??? self.db_path = db_path\n",
    "        self.user_data_path = user_data_path\n",
    "        self.image_base_path = image_base_path\n",
    "\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "\n",
    "        logger.info(f\"Initializing inference class {self.name}\")\n",
    "\n",
    "        self.device = self.device or get_device()\n",
    "        self.category_map = self.get_labels(self.labels_path)\n",
    "        self.num_classes = self.num_classes or len(self.category_map)\n",
    "        self.weights = self.get_weights(self.weights_path)\n",
    "        self.transforms = self.get_transforms()\n",
    "        #KBE??? self.queue = self.get_queue()\n",
    "        #KBE??? self.dataset = self.get_dataset()\n",
    "        self.dataset = None\n",
    "        self.dataloader = self.get_dataloader()\n",
    "        logger.info(\n",
    "            f\"Loading {self.type} model (stage: {self.stage}) for {self.name} with {len(self.category_map or [])} categories\"\n",
    "        )\n",
    "        self.model = self.get_model()\n",
    "\n",
    "    @classmethod\n",
    "    def get_key(cls):\n",
    "        if hasattr(cls, \"key\") and cls.key:  # type: ignore\n",
    "            return cls.key  # type: ignore\n",
    "        else:\n",
    "            return slugify(cls.name)\n",
    "    \n",
    "    def get_weights(self, weights_path):\n",
    "        if weights_path:\n",
    "            return get_or_download_file(\n",
    "                weights_path, self.user_data_path, prefix=\"models\"\n",
    "            )\n",
    "        else:\n",
    "            logger.warn(f\"No weights specified for model {self.name}\")\n",
    "\n",
    "    def get_labels(self, labels_path):\n",
    "        if labels_path:\n",
    "            local_path = get_or_download_file(\n",
    "                labels_path, self.user_data_path, prefix=\"models\"\n",
    "            )\n",
    "\n",
    "            with open(local_path) as f:\n",
    "                labels = json.load(f)\n",
    "\n",
    "            if self.lookup_gbif_names:\n",
    "                \"\"\"\n",
    "                Use this if you want to store name strings instead of taxon IDs.\n",
    "                Taxon IDs are helpful for looking up additional information about the species\n",
    "                such as the genus and family.\n",
    "                \"\"\"\n",
    "                #KBE??? from trapdata.ml.utils import replace_gbif_id_with_name\n",
    "                from ml.utils import replace_gbif_id_with_name\n",
    "\n",
    "                string_labels = {}\n",
    "                for label, index in labels.items():\n",
    "                    string_label = replace_gbif_id_with_name(label)\n",
    "                    string_labels[string_label] = index\n",
    "\n",
    "                logger.info(f\"Replacing GBIF IDs with names in {local_path}\")\n",
    "                # Backup the original file\n",
    "                local_path.rename(local_path.with_suffix(\".bak\"))\n",
    "                with open(local_path, \"w\") as f:\n",
    "                    json.dump(string_labels, f)\n",
    "\n",
    "            # @TODO would this be faster as a list? especially when getting the labels of multiple\n",
    "            # indexes in one prediction\n",
    "            index_to_label = {index: label for label, index in labels.items()}\n",
    "\n",
    "            return index_to_label\n",
    "        else:\n",
    "            return {}\n",
    "\n",
    "    def get_model(self) -> torch.nn.Module:\n",
    "        \"\"\"\n",
    "        This method must be implemented by a subclass.\n",
    "\n",
    "        Example:\n",
    "\n",
    "        model = torch.nn.Module()\n",
    "        checkpoint = torch.load(self.weights, map_location=self.device)\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        model = model.to(self.device)\n",
    "        model.eval()\n",
    "        return model\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_transforms(self) -> torchvision.transforms.Compose:\n",
    "        \"\"\"\n",
    "        This method must be implemented by a subclass.\n",
    "\n",
    "        Example:\n",
    "\n",
    "        transforms = torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        return transforms\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    #KBE??? def get_queue(self) -> QueueManager:\n",
    "        \"\"\"\n",
    "        This method must be implemented by a subclass.\n",
    "        Example:\n",
    "\n",
    "        from trapdata.db.models.queue import DetectedObjectQueue\n",
    "        def get_queue(self):\n",
    "            return DetectedObjectQueue(self.db_path, self.image_base_path)\n",
    "        \"\"\"\n",
    "        #KBE??? raise NotImplementedError\n",
    "\n",
    "    def get_dataset(self) -> torch.utils.data.Dataset:\n",
    "        \"\"\"\n",
    "        This method must be implemented by a subclass.\n",
    "\n",
    "        Example:\n",
    "\n",
    "        dataset = torch.utils.data.Dataset()\n",
    "        return dataset\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_dataloader(self):\n",
    "        \"\"\"\n",
    "        Prepare dataloader for streaming/iterable datasets from database\n",
    "        \"\"\"\n",
    "        if self.single:\n",
    "            logger.info(\n",
    "                f\"Preparing dataloader with batch size of {self.batch_size} in single worker mode.\"\n",
    "            )\n",
    "        else:\n",
    "            logger.info(\n",
    "                f\"Preparing dataloader with batch size of {self.batch_size} and {self.num_workers} workers.\"\n",
    "            )\n",
    "        self.dataloader = torch.utils.data.DataLoader(\n",
    "            self.dataset,\n",
    "            num_workers=0 if self.single else self.num_workers,\n",
    "            persistent_workers=False if self.single else True,\n",
    "            shuffle=False,\n",
    "            pin_memory=False if self.single else True,  # @TODO review this\n",
    "            batch_size=None,  # Recommended setting for streaming datasets\n",
    "            batch_sampler=None,  # Recommended setting for streaming datasets\n",
    "        )\n",
    "        return self.dataloader\n",
    "\n",
    "    def predict_batch(self, batch):\n",
    "        batch_input = batch.to(\n",
    "            self.device,\n",
    "            non_blocking=True,  # Block while in development, are we already in a background process?\n",
    "        )\n",
    "        batch_output = self.model(batch_input)\n",
    "        return batch_output\n",
    "\n",
    "    def post_process_single(self, item):\n",
    "        return item\n",
    "\n",
    "    def post_process_batch(self, batch_output):\n",
    "        return [self.post_process_single(item) for item in batch_output]\n",
    "        # Had problems with this generator and multiprocessing\n",
    "        # for item in batch_output:\n",
    "        #     yield self.post_process_single(item)\n",
    "\n",
    "    def save_results(self, item_ids, batch_output):\n",
    "        logger.warn(\"No save method configured for model. Doing nothing with results\")\n",
    "        return None\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def run(self):\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        for i, batch in enumerate(self.dataloader):\n",
    "            if not batch:\n",
    "                # @TODO review this once we switch to streaming IterableDataset\n",
    "                logger.info(f\"Batch {i+1} is empty, skipping\")\n",
    "                continue\n",
    "\n",
    "            item_ids, batch_input = batch\n",
    "\n",
    "            logger.info(\n",
    "                f\"Processing batch {i+1}, about {len(self.dataloader)} remaining\"\n",
    "            )\n",
    "\n",
    "            # @TODO the StopWatch doesn't seem to work when there are multiple workers,\n",
    "            # it always returns 0 seconds.\n",
    "            with StopWatch() as batch_time:\n",
    "                #KBE??? with start_transaction(op=\"inference_batch\", name=self.name):\n",
    "                batch_output = self.predict_batch(batch_input)\n",
    "\n",
    "            seconds_per_item = batch_time.duration / len(batch_output)\n",
    "            logger.info(\n",
    "                f\"Inference time for batch: {batch_time}, \"\n",
    "                f\"Seconds per item: {round(seconds_per_item, 2)}\"\n",
    "            )\n",
    "\n",
    "            batch_output = list(self.post_process_batch(batch_output))\n",
    "            item_ids = item_ids.tolist()\n",
    "            logger.info(f\"Saving {len(item_ids)} results\")\n",
    "            self.save_results(item_ids, batch_output)\n",
    "            logger.info(f\"{self.name} Batch -- Done\")\n",
    "\n",
    "        logger.info(f\"{self.name} -- Done\")\n",
    "\n",
    "class Resnet50(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            config: provides parameters for model generation\n",
    "        \"\"\"\n",
    "        super(Resnet50, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.backbone = torchvision.models.resnet50(weights=\"DEFAULT\")\n",
    "        out_dim = self.backbone.fc.in_features\n",
    "\n",
    "        self.backbone = torch.nn.Sequential(*list(self.backbone.children())[:-2])\n",
    "        self.avgpool = torch.nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.classifier = torch.nn.Linear(out_dim, self.num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class Resnet50Classifier(InferenceBaseClass):\n",
    "    input_size = 300\n",
    "\n",
    "    def get_model(self):\n",
    "        num_classes = len(self.category_map)\n",
    "        model = Resnet50(num_classes=num_classes)\n",
    "        model = model.to(self.device)\n",
    "        # state_dict = torch.hub.load_state_dict_from_url(weights_url)\n",
    "        checkpoint = torch.load(self.weights, map_location=self.device)\n",
    "        # The model state dict is nested in some checkpoints, and not in others\n",
    "        state_dict = checkpoint.get(\"model_state_dict\") or checkpoint\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def get_transforms(self):\n",
    "        mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "        return torchvision.transforms.Compose(\n",
    "            [\n",
    "                torchvision.transforms.Resize((self.input_size, self.input_size)),\n",
    "                torchvision.transforms.ToTensor(),\n",
    "                torchvision.transforms.Normalize(mean, std),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def post_process_batch(self, output):\n",
    "        predictions = torch.nn.functional.softmax(output, dim=1)\n",
    "        predictions = predictions.cpu().numpy()\n",
    "\n",
    "        categories = predictions.argmax(axis=1)\n",
    "        labels = [self.category_map[cat] for cat in categories]\n",
    "        scores = predictions.max(axis=1).astype(float)\n",
    "\n",
    "        result = list(zip(labels, scores, categories))\n",
    "        logger.debug(f\"Post-processing result batch: {result}\")\n",
    "        return result\n",
    "\n",
    "\n",
    "class Resnet50ClassifierLowRes(Resnet50Classifier):\n",
    "    input_size = 128\n",
    "\n",
    "    def get_model(self):\n",
    "        #KBE??? model = torchvision.models.resnet50(weights=None) \n",
    "        model = torchvision.models.resnet50(pretrained=False) # Older version of torchvision\n",
    "        num_ftrs = model.fc.in_features\n",
    "        assert (\n",
    "            self.num_classes\n",
    "        ), f\"Number of classes could not be determined for for {self.name}\"\n",
    "        model.fc = torch.nn.Linear(num_ftrs, self.num_classes)\n",
    "        model = model.to(self.device)\n",
    "        assert self.weights, f\"No weights path configured for {self.name}\"\n",
    "        checkpoint = torch.load(self.weights, map_location=self.device)\n",
    "        state_dict = checkpoint.get(\"model_state_dict\") or checkpoint\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "class SpeciesClassifier(InferenceBaseClass):\n",
    "    stage = 4\n",
    "    type = \"fine_grained_classifier\"\n",
    "\n",
    "    #KBE??? def get_queue(self) -> UnclassifiedObjectQueue:\n",
    "    #KBE???     return UnclassifiedObjectQueue(self.db_path, self.image_base_path)\n",
    "\n",
    "    def get_dataset(self):\n",
    "        dataset = ClassificationIterableDatabaseDataset(\n",
    "            queue=self.queue,\n",
    "            image_transforms=self.get_transforms(),\n",
    "            batch_size=self.batch_size,\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "    def save_results(self, object_ids, batch_output):\n",
    "        # Here we are saving the specific taxon labels\n",
    "        classified_objects_data = [\n",
    "            {\n",
    "                \"specific_label\": label,\n",
    "                \"specific_label_score\": score,\n",
    "                \"model_name\": self.name,\n",
    "                \"in_queue\": True,  # Put back in queue for the feature extractor & tracking\n",
    "            }\n",
    "            for label, score in batch_output\n",
    "        ]\n",
    "        #KBE??? save_classified_objects(self.db_path, object_ids, classified_objects_data)\n",
    "\n",
    "\n",
    "class UKDenmarkMothSpeciesClassifierMixedResolution(\n",
    "    SpeciesClassifier, Resnet50ClassifierLowRes\n",
    "):\n",
    "    \"\"\"\n",
    "    Training log and weights can be found here:\n",
    "    https://wandb.ai/moth-ai/uk-denmark/artifacts/model/model/v0/overview\n",
    "\n",
    "    Species checklist used for training:\n",
    "    https://github.com/adityajain07/mothAI/blob/main/species_lists/UK-Denmark-Moth-List_11July2022.csv\n",
    "    \"\"\"\n",
    "\n",
    "    name = \"UK & Denmark Species Classifier\"\n",
    "    description = \"Trained on April 3, 2023 using mix of low & med resolution images.\"\n",
    "    weights_path = (\n",
    "        \"https://object-arbutus.cloud.computecanada.ca/ami-models/moths/classification/\"\n",
    "        \"uk-denmark-moths-mixedres-20230403_140131_30.pth\"\n",
    "    )\n",
    "    labels_path = (\n",
    "        \"https://object-arbutus.cloud.computecanada.ca/ami-models/moths/classification/\"\n",
    "        \"01-moths-ukdenmark_v2_category_map_species_names.json\"\n",
    "    )\n",
    "\n",
    "def classifySpeciesBatch(classifier, batch):\n",
    "    predictions = classifier.predict_batch(batch)\n",
    "    predictions = predictions.detach()\n",
    "    predLabelsScores = classifier.post_process_batch(predictions)\n",
    "    return predLabelsScores\n",
    "\n",
    "    lines = []\n",
    "    for pred in predLabelsScores:\n",
    "        predicted_label_text = pred[0]\n",
    "        confidence_value = round(pred[1]*10000)/100\n",
    "        predicted_label = pred[2]\n",
    "        line = f\"{predicted_label_text},{predicted_label},{confidence_value}\"\n",
    "        lines.append(line)\n",
    "    \n",
    "    return lines, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa90c3-79ed-4b31-be8f-13a2801694f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=UKDenmarkMothSpeciesClassifierMixedResolution(\"/home/george/tmp/models\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a805430b-1cfb-457a-8ffb-3f036ac9f6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get one batch of image\n",
    "img_dir = Path(\"/home/george/codes/lepinet/data/flemming_ucloud/images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39586715-6792-4d4d-9676-0944160b6b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_filenames = list(img_dir.glob('*/*.jpg'))\n",
    "img_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b38bb89-3abb-46de-96ba-5acdb9e4e370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make a prediction on all images\n",
    "batch_size = 64\n",
    "img_size = 128\n",
    "\n",
    "# preds = []\n",
    "\n",
    "for i in tqdm(range(0,len(img_filenames),batch_size)):\n",
    "    bs = min(batch_size, len(img_filenames)-i)\n",
    "    batch = torch.FloatTensor(bs, 3, img_size, img_size) \n",
    "    \n",
    "    for j in range(bs):\n",
    "        image = cv2.imread(img_filenames[i+j])\n",
    "        image = cv2.resize(image, (img_size, img_size))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        image = torchvision.transforms.ToTensor()(image) #.unsqueeze_(0)\n",
    "        batch[j] = image #/255.0\n",
    "    preds += classifySpeciesBatch(classifier, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10a2a9a-27a8-41d0-8fa5-72ef45ceeec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preds), len(img_filenames), len(img_filenames)-len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c94bea-5638-4437-a8a3-333abb460f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:10], img_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7f0ac1-15bc-4194-8a29-9d2c93074f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_key(session, scientificName=None, usageKey=None, rank='SPECIES', order='Lepidoptera'):\n",
    "    url = \"https://api.gbif.org/v1/species/match?\"\n",
    "    assert usageKey is not None or scientificName is not None, \"One of scientificName or usageKey must be defined.\"\n",
    "\n",
    "    if usageKey is not None:\n",
    "        url += f\"usageKey={usageKey}&\"\n",
    "    if scientificName is not None:\n",
    "        if scientificName=='Tethea or': return 5142971 # bug fix\n",
    "        url += f\"scientificName={scientificName}&\"\n",
    "    if rank is not None:\n",
    "        url += f\"rank={rank}&\"\n",
    "    if order is not None:\n",
    "        url += f\"order={order}\"\n",
    "\n",
    "    async with session.get(url) as response:\n",
    "        r = await response.json()\n",
    "        # return r if not 'canonicalName' in r.keys() else r['canonicalName']\n",
    "        return r if not 'speciesKey' in r.keys() else r['speciesKey']\n",
    "\n",
    "async def get_all_keys(vocab):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = [get_key(session, scientificName=k, rank=None) for k in vocab]\n",
    "        return await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316e508-fed2-45c8-a65f-25e60c4ac918",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_names = np.unique([e[0] for e in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a5d856-ec15-442d-917b-76c7417f7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4d005-9894-4626-88a6-5b768a1b1c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif_keys=asyncio.run(get_all_keys(unique_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8a3e2a-f3dd-48c5-91e5-14480489df74",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "name2key = {str(k):v for k,v in zip(unique_names, gbif_keys)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd20636-1f37-43fd-a248-1e75a3d08a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_id=[]\n",
    "filename=[]\n",
    "level=[]\n",
    "label=[]\n",
    "prediction=[]\n",
    "confidence=[]\n",
    "threshold=[] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cffab4-f73c-40f7-8ec1-c4fd315b6f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(img_filenames):\n",
    "    instance_id += [i]\n",
    "    filename += [f]\n",
    "    level += [0]\n",
    "    label += [f.parent.name]\n",
    "    prediction += [name2key[preds[i][0]]]\n",
    "    confidence += [float(preds[i][1])]\n",
    "    threshold += [0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989214a0-b28a-4591-b88d-2fb5203bb93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'instance_id':instance_id,\n",
    "    'filename':filename,\n",
    "    'level':level,\n",
    "    'label':label,\n",
    "    'prediction':prediction,\n",
    "    'confidence':confidence,\n",
    "    'threshold':threshold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cf28ee-4195-4723-9f3d-b3722bcb757f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c5585-22dd-4333-8832-377d5a0148b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/george/codes/lepinet/data/flemming_ucloud/ukdenmark_model/ukdk.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35cc9b-076e-4975-8c07-96d7ff4c565e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
