{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "from PIL import Image\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_path=Path(\"/home/george/codes/lepinet/data/mini/0013397-241007104925546_processing_metadata_postprocessed.parquet\")\n",
    "images_path=Path(\"/home/george/codes/lepinet/data/mini/images\")\n",
    "root_path=Path(\"/home/george/codes/lepinet/data/mini\")\n",
    "export_path=Path(\"/home/george/codes/lepinet/data/mini/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = df.iloc[0]\n",
    "row.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = images_path / row[\"speciesKey\"] / row[\"filename\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path, os.path.isfile(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(sum(df['set'].isin(['test_ood', '0'])), \n",
    "sum(df['set'].isin(['test_ood'])),\n",
    "sum(df['set'].isin(['0']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_df(df, remove_in=[], keep_in=[]):\n",
    "    # Filter out 'test_ood' rows and 'test_in' rows\n",
    "    if len(remove_in)>0:\n",
    "        df = df[~df['set'].isin(remove_in)]\n",
    "    if len(keep_in)>0:\n",
    "        df = df[df['set'].isin(keep_in)]\n",
    "    def generate_image_path(row):\n",
    "        return Path(str(row['speciesKey'])) / row['filename']\n",
    "\n",
    "    # Apply the function to create the image paths\n",
    "    df['image_path'] = df.apply(generate_image_path, axis=1)\n",
    "    # Add a column to specify whether the row is for training or validation\n",
    "    df['is_valid'] = df['set'] == '0'\n",
    "    # Define the hierarchical levels\n",
    "    hierarchy_levels = [\"familyKey\", \"genusKey\", \"speciesKey\"]\n",
    "\n",
    "    # Create a function to extract the labels at different hierarchy levels\n",
    "    def get_hierarchy_labels(row):\n",
    "        return ' '.join(map(str, [row[level] for level in hierarchy_levels]))\n",
    "\n",
    "    # Add a column with hierarchy labels\n",
    "    df['hierarchy_labels'] = df.apply(get_hierarchy_labels, axis=1)\n",
    "    # Keep only the columns needed for ImageDataLoaders\n",
    "    df = df[['image_path', 'hierarchy_labels', 'is_valid']]\n",
    "    return df\n",
    "\n",
    "df=prepare_df(df.copy(), remove_in=['test_ood'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = ImageDataLoaders.from_df(\n",
    "    df,\n",
    "    images_path,\n",
    "    valid_col='is_valid',\n",
    "    label_delim=' ',\n",
    "    item_tfms=Resize(460),\n",
    "    batch_tfms=aug_transforms(size=224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_macro = F1ScoreMulti(thresh=0.5, average='macro')\n",
    "f1_macro.name = 'F1(macro)'\n",
    "f1_samples = F1ScoreMulti(thresh=0.5, average='samples')\n",
    "f1_samples.name = 'F1(samples)'\n",
    "learn = vision_learner(dls, resnet50, metrics=[partial(accuracy_multi, thresh=0.5), f1_macro, f1_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res=learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.valley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(10, 2e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "os.makedirs(export_path, exist_ok=True)\n",
    "\n",
    "model_path = export_path / \"00_lepi_mini_model1\"\n",
    "learn.export(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -alh /home/george/codes/lepinet/data/mini/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = export_path / \"00_lepi_mini_model1\"\n",
    "\n",
    "learn = load_learner(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I need to specify the vocab of the MultiCategoryBlock\n",
    "\n",
    "So I need to go down in the layered architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab=[]\n",
    "hierarchy_levels = [\"familyKey\", \"genusKey\", \"speciesKey\"]\n",
    "for col in hierarchy_levels:\n",
    "    vocab += pd.unique(df[col]).tolist()\n",
    "vocab = pd.Series(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's redefine the dataloader\n",
    "\n",
    "datablock = DataBlock(\n",
    "    blocks=(ImageBlock, MultiCategoryBlock(vocab=vocab)),\n",
    "    splitter=ColSplitter(),\n",
    "    get_x=ColReader(0, pref=images_path),\n",
    "    get_y=ColReader(1, label_delim=' '),\n",
    "    item_tfms=Resize(460),\n",
    "    batch_tfms=aug_transforms(size=224)\n",
    ")\n",
    "dls = datablock.dataloaders(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
