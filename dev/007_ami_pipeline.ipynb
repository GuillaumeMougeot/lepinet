{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63e339f",
   "metadata": {},
   "source": [
    "# AMI pipeline\n",
    "\n",
    "ERDA downloader\n",
    "\n",
    "flat-bug\n",
    "\n",
    "order classifier\n",
    "\n",
    "species classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a9a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from inspect import getmembers_static\n",
    "from os.path import join\n",
    "from types import SimpleNamespace\n",
    "import importlib\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "from fastai.vision.all import load_learner, CategoryMap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "kavi_pipeline = importlib.import_module(\"009_kavi_pipeline_integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c94584",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_path = \"/home/george/codes/lepinet/data/lepi/models/04-lepi-prod_model1-save-hierarchy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"/home/george/codes/lepinet/data/lepi/images/1730978/80e33d32259a9f4f034b2cb94f98ce8b5b70bfcd.jpeg\"\n",
    "img_dir = \"/home/george/codes/lepinet/data/lepi/images/1730978\"\n",
    "kavi_img_path = \"/home/george/codes/lepinet/data/kavi/20240708225609-snapshot.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeea7b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn=load_learner(learner_path, cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38384189",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471bdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(learn.dls.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abb067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(learn.dls.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb61fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(learn.dls.loaders[1].after_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "getmembers_static(learn.dls.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b3387",
   "metadata": {},
   "outputs": [],
   "source": [
    "getmembers_static(learn.dls.loaders[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352edc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.valid==learn.dls.loaders[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.valid.new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23ec4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(learn.dls.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa9eecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=learn.dls.loaders[1].after_item(Image.open(img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40934c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "getmembers_static(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f064f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [join(img_dir, f) for f in os.listdir(img_dir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149065fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(learn.dls.valid_ds.tls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a69c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.valid_ds.tls[0].dataloaders(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54136ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "getmembers_static(learn.dls.valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc96d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.valid.after_item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73453d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(filenames,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d5a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48621eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "getmembers_static(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0331b743",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs=[]\n",
    "n_limit = 16\n",
    "to_tensor = transforms.ToTensor()\n",
    "for i, img_path in enumerate(os.listdir(img_dir)):\n",
    "    if i == n_limit:\n",
    "        break\n",
    "    img=Image.open(join(img_dir, img_path))\n",
    "    img=np.array(img)\n",
    "    imgs.append(img)\n",
    "len(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f2de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareCrop(imageCrop, img_size=128):\n",
    "    image = cv2.resize(imageCrop, (img_size, img_size))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image)\n",
    "    image = transforms.ToTensor()(image) #.unsqueeze_(0)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c138d4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(imgs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e8b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67654163",
   "metadata": {},
   "outputs": [],
   "source": [
    "with learn.no_bar(), learn.no_logging():\n",
    "    preds, _ = learn.get_preds(dl=test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5229763",
   "metadata": {},
   "outputs": [],
   "source": [
    "getmembers_static(learn.dls.loaders[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27640dda",
   "metadata": {},
   "source": [
    "Test Kavi images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=kavi_pipeline.FastaiSpeciesClassifier(speciesModelPath=\"/home/george/codes/lepinet/data/lepi/models/04-lepi-prod_model1-save-hierarchy-id2name\", output_type='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c80879",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(kavi_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7813bfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(kavi_img_path)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facd0934",
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes=[\n",
    "    {\"x1\": 3240,\"x2\": 3392,\"y1\": 277, \"y2\": 433},\n",
    "    {\"x1\": 3024,\"x2\": 3112,\"y1\": 839,\"y2\": 983},\n",
    "    {\"x1\": 816,\"x2\": 921,\"y1\": 170,\"y2\": 343}\n",
    "]\n",
    "detections = []\n",
    "for i,b in enumerate(bboxes):\n",
    "    bbox = SimpleNamespace(**b)\n",
    "    detection = SimpleNamespace(id=f'{i+1}', bbox=bbox)\n",
    "    detections.append(detection)\n",
    "\n",
    "batch = classifier.batchFromDetections(image, detections)\n",
    "results = classifier.classifySpeciesBatch(batch)\n",
    "\n",
    "# Print results\n",
    "for i, res in enumerate(results):\n",
    "    print(\"\\n--- Detection Result ---\")\n",
    "    print(\"bboxes:\", bboxes[i])\n",
    "    print(\"Detection ID:\", res[\"id\"])\n",
    "    print(\"Predicted Labels (Hierarchy):\", res[\"label\"])\n",
    "    print(\"Predicted Labels ID (Hierarchy):\", res[\"labelId\"])\n",
    "    print(\"Confidence Scores:\", res[\"confidence_value\"])\n",
    "    \n",
    "    # plt.imshow(batch[\"imagesInBatch\"][i])\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in batch[\"imagesInBatch\"]:\n",
    "    plt.imshow(b)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a77b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figsize()\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf4b5d9",
   "metadata": {},
   "source": [
    "Deprecated code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ce90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Create a custom test dataset\n",
    "    class PILImagesList(L):\n",
    "        def __getitem__(self, idx):\n",
    "            return pil_images[idx]\n",
    "    \n",
    "    # Create a custom test dataset class that directly accepts PIL images\n",
    "    class PILImagesDataset(Dataset):\n",
    "        def __init__(self, images):\n",
    "            self.images = images\n",
    "            \n",
    "        def __len__(self):\n",
    "            return len(self.images)\n",
    "            \n",
    "        def __getitem__(self, idx):\n",
    "            # Return the PIL image and a dummy label (0)\n",
    "            return PILItem(self.images[idx], None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286f8d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_level_idx(vocab, hierarchy):\n",
    "    \"\"\"\n",
    "    Returns a list of integers of the size of vocab indicating the hierarchical level of the taxa at index i.\n",
    "    - Species is level 0, Genus 1, Family 2, etc.\n",
    "    - Missing values are noted with -1.\n",
    "\n",
    "    Args:\n",
    "    - vocab (list): List of taxa names to find levels for.\n",
    "    - hierarchy (dict): Nested dictionary representing taxonomic hierarchy.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Array of level indices for each taxa in vocab.\n",
    "    \"\"\"\n",
    "    level_lookup = {}\n",
    "\n",
    "    def traverse(node, level=0):\n",
    "        \"\"\"Recursively traverse the hierarchy and store levels.\"\"\"\n",
    "        for key, subnode in node.items():\n",
    "            level_lookup[key] = level  # Assign level to the taxon\n",
    "            if isinstance(subnode, dict):\n",
    "                traverse(subnode, level + 1)\n",
    "            elif isinstance(subnode, list):  # Leaf nodes (species level)\n",
    "                for species in subnode:\n",
    "                    level_lookup[species] = level + 1\n",
    "\n",
    "    # Build the level lookup dictionary\n",
    "    traverse(hierarchy)  # Start from -1 so species end up at level 0\n",
    "\n",
    "    # Assign levels to vocab, default to -1 if missing\n",
    "    indices = np.array([level_lookup.get(v, -1) for v in vocab], dtype=int)\n",
    "\n",
    "    # Invert the indices, so species is 0, genus is 1 etc\n",
    "    # indices = np.where(indices < 0, indices, indices.max()-indices)\n",
    "\n",
    "    # Warning for missing values\n",
    "    missing_count = np.sum(indices == -1)\n",
    "    if missing_count > 0:\n",
    "        print(f\"[Warning] Missing values in taxa dictionary: {missing_count}.\")\n",
    "\n",
    "    return indices\n",
    "\n",
    "def split_preds(preds:torch.Tensor, indices:np.ndarray):\n",
    "    \"\"\"Returns split preds using indices.\n",
    "\n",
    "    `preds` is a batch of predictions.\n",
    "    \"\"\"\n",
    "    out_preds = []\n",
    "    indices = torch.from_numpy(indices)\n",
    "    for i in range(indices.max()+1):\n",
    "        out_preds += [preds[:,indices==i].cpu().numpy()]\n",
    "    return out_preds\n",
    "\n",
    "def get_pred_conf(preds:torch.Tensor, vocab:CategoryMap, indices:np.ndarray):\n",
    "    \"\"\"Returns predicted labels and confidence for each pred and for each \n",
    "    hierarchy level.\n",
    "\n",
    "    `preds` is a batch of predictions.\n",
    "    \"\"\"\n",
    "    out_preds = []\n",
    "    out_confs = []\n",
    "    indices = torch.from_numpy(indices)\n",
    "    for i in range(indices.max()+1):\n",
    "        one_level_pred = preds[:,indices==i].cpu().numpy()\n",
    "        one_level_prd = vocab[indices==i][one_level_pred.argmax(axis=1)]\n",
    "        one_level_cnf = one_level_pred.max(axis=1)\n",
    "        out_preds += [one_level_prd]\n",
    "        out_confs += [one_level_cnf]\n",
    "    return np.array(out_preds).swapaxes(0,1), np.array(out_confs).swapaxes(0,1)\n",
    "\n",
    "\n",
    "indices=gen_level_idx(learn.dls.vocab, learn.hierarchy)\n",
    "prds, cnfs = get_pred_conf(preds, learn.dls.vocab, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5197298c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prds, cnfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5800f0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncSFTPParams(TypedDict):\n",
    "    host: str\n",
    "    port: int\n",
    "    username: str\n",
    "    password: str\n",
    "    client_keys: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3c5af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sftp_params=AsyncSFTPParams(\n",
    "        host=\"io.erda.au.dk\",\n",
    "        port=2222,\n",
    "        username=\"gmo@ecos.au.dk\",\n",
    "        client_keys=[\"~/.ssh/id_rsa\"])\n",
    "\n",
    "remotepaths = \"AMI/storage/mambo/2024/uva/NL1/2024_07_18\"\n",
    "localpath = \"/home/george/codes/lepinet/data/mambo/images\"\n",
    "\n",
    "async with asyncssh.connect(**sftp_params) as conn:\n",
    "    async with conn.start_sftp_client() as sftp:\n",
    "        sftp.get(remotepaths, localpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd12f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AMIPipeline:\n",
    "    def __init__(\n",
    "        self,\n",
    "        remote_dir: str,\n",
    "        local_dir: str,\n",
    "        max_queue_size: int = 16\n",
    "    ):\n",
    "        os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "        # Queues for managing pipeline stages\n",
    "        self.download_queue = asyncio.Queue(maxsize=max_queue_size)\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
