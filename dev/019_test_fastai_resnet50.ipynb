{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ffddbc-2244-48b6-acf2-dcfb2ff935f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6585cd8a-d7ef-419c-a945-028335a159a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import urllib.request\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from fastai.vision.all import CategoryMap, load_learner\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms\n",
    "import datetime, time\n",
    "import json\n",
    "from typing import Union\n",
    "import pathlib\n",
    "import urllib\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import aiohttp\n",
    "import asyncio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ERDA_MODELS = \"https://anon.erda.au.dk/share_redirect/C1nJdS1jtA/{}\"\n",
    "DEFAULT_MODEL = \"00_eulepi.pkl\"\n",
    "MODEL_LOCAL_PATH=\"{}\"\n",
    "\n",
    "def gen_level_idx(vocab, hierarchy):\n",
    "    \"\"\"\n",
    "    Returns a list of integers of the size of vocab indicating the hierarchical level of the taxa at index i.\n",
    "    - Species is level 0, Genus 1, Family 2, etc.\n",
    "    - Missing values are noted with -1.\n",
    "\n",
    "    Args:\n",
    "    - vocab (list): List of taxa names to find levels for.\n",
    "    - hierarchy (dict): Nested dictionary representing taxonomic hierarchy.\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray: Array of level indices for each taxa in vocab.\n",
    "    \"\"\"\n",
    "    level_lookup = {}\n",
    "\n",
    "    def traverse(node, level=0):\n",
    "        \"\"\"Recursively traverse the hierarchy and store levels.\"\"\"\n",
    "        for key, subnode in node.items():\n",
    "            level_lookup[key] = level  # Assign level to the taxon\n",
    "            if isinstance(subnode, dict):\n",
    "                traverse(subnode, level + 1)\n",
    "            elif isinstance(subnode, list):  # Leaf nodes (species level)\n",
    "                for species in subnode:\n",
    "                    level_lookup[species] = level + 1\n",
    "\n",
    "    # Build the level lookup dictionary\n",
    "    traverse(hierarchy)  # Start from -1 so species end up at level 0\n",
    "\n",
    "    # Assign levels to vocab, default to -1 if missing\n",
    "    indices = np.array([level_lookup.get(v, -1) for v in vocab], dtype=int)\n",
    "\n",
    "    # Invert the indices, so species is 0, genus is 1 etc\n",
    "    indices = np.where(indices < 0, indices, indices.max()-indices)\n",
    "\n",
    "    # Warning for missing values\n",
    "    missing_count = np.sum(indices == -1)\n",
    "    if missing_count > 0:\n",
    "        print(f\"[Warning] Missing values in taxa dictionary: {missing_count}.\")\n",
    "\n",
    "    return indices\n",
    "\n",
    "def get_pred_conf(preds:torch.Tensor, vocab:CategoryMap, indices:np.ndarray):\n",
    "    \"\"\"Returns predicted labels and confidence for each pred and for each \n",
    "    hierarchy level.\n",
    "\n",
    "    `preds` is a batch of predictions.\n",
    "    \"\"\"\n",
    "    out_preds = []\n",
    "    out_confs = []\n",
    "    indices = torch.from_numpy(indices)\n",
    "    for i in range(indices.max()+1):\n",
    "        one_level_pred = preds[:,indices==i].cpu().numpy()\n",
    "        one_level_prd = vocab[indices==i][one_level_pred.argmax(axis=1)]\n",
    "        one_level_cnf = one_level_pred.max(axis=1)\n",
    "        out_preds += [one_level_prd]\n",
    "        out_confs += [one_level_cnf]\n",
    "    return np.array(out_preds).swapaxes(0,1), np.array(out_confs).swapaxes(0,1)\n",
    "\n",
    "class FastaiSpeciesClassifier:\n",
    "    valid_type = ['all', 'species', 'best']\n",
    "    f\"\"\"\n",
    "    Prediciton class for the species classifier trained with fastai.\n",
    "\n",
    "    Args:\n",
    "    - speciesModelPath (str): Path to the species model, if None download it from a ERDA link.\n",
    "    - device (str): Device to run the computations. Either cpu or cuda.\n",
    "    - output_type (str): Type of the output: one of {valid_type}. 'all' outputs a list of the best model prediction per hierarchy level, in the following order: species, genus, family. 'species' only outputs the species level. 'best' only outputs the lowest ranked predictions with a confidence above `th`.\n",
    "    - th (float): Confidence threshold.\n",
    "    \"\"\"\n",
    "    def __init__(self, speciesModelPath:str=None, device='cuda', output_type: str='species', th: float=0.5):\n",
    "        assert output_type in self.valid_type, f\"Error: `output_type` must be one of {self.valid_type} but found {output_type}\"\n",
    "\n",
    "        self.log = logging.getLogger(__name__)\n",
    "\n",
    "        # Download model from ERDA if not found locally\n",
    "        if speciesModelPath is None:\n",
    "            speciesModelPath = MODEL_LOCAL_PATH.format(DEFAULT_MODEL)\n",
    "        if not Path(speciesModelPath).is_file() or\\\n",
    "            not Path(DEFAULT_MODEL).exists():\n",
    "            self.log.info(f\"Model not found. Downloading from {ERDA_MODELS.format(DEFAULT_MODEL)}\")\n",
    "            url = ERDA_MODELS.format(DEFAULT_MODEL)\n",
    "            with urllib.request.urlopen(url) as response, open(speciesModelPath, 'wb') as out_file:\n",
    "                out_file.write(response.read())\n",
    "        else:\n",
    "            print(f\"Found model in {speciesModelPath}\")\n",
    "\n",
    "        self.log.info(\"Moth species model path %s\", speciesModelPath)\n",
    "        # Load fastai Learner instead of previous speciesClassifier\n",
    "        self.speciesLearner = load_learner(speciesModelPath, cpu=(device == 'cpu'))\n",
    "        self.speciesLearner.model.eval()\n",
    "        self.id2name = self.speciesLearner.id2name\n",
    "\n",
    "        indices = gen_level_idx(\n",
    "            self.speciesLearner.dls.vocab,\n",
    "            self.speciesLearner.hierarchy)\n",
    "    \n",
    "        self.get_pred_conf = partial(\n",
    "            get_pred_conf, \n",
    "            vocab=self.speciesLearner.dls.vocab,\n",
    "            indices=indices,)\n",
    "    \n",
    "        self.output_type = output_type\n",
    "        self.th = th\n",
    "\n",
    "    def extractCrop(self, image, bbox):\n",
    "        if image is None:\n",
    "            print(\"Error image cannot be none\")\n",
    "            raise Exception(\"None image in extract crop\")\n",
    "        x1 = bbox.x1\n",
    "        x2 = bbox.x2\n",
    "        y1 = bbox.y1\n",
    "        y2 = bbox.y2\n",
    "        image_crop = image[y1:y2, x1:x2]\n",
    "        return image_crop\n",
    "\n",
    "    def batchFromDetections(self, image, detections):\n",
    "        if image is None:\n",
    "            print(\"Image must not be None\")\n",
    "            raise Exception(\"None image not allowed in batchFromDetections\")\n",
    "        print(f\"Batching {len(detections)} detections\")\n",
    "        print(f\"Batching {detections} detections\")\n",
    "        imagesInBatch = []\n",
    "        detection_ids = []\n",
    "        for idx in range(len(detections)):\n",
    "            print(f\"Adding: {detections[idx]}\")\n",
    "            bbox = detections[idx].bbox\n",
    "            im = self.extractCrop(image, bbox)\n",
    "            imagesInBatch.append(np.array(im))\n",
    "            detection_ids.append(detections[idx].id)\n",
    "        return { \"imagesInBatch\": imagesInBatch, \"detection_ids\": detection_ids }\n",
    "\n",
    "    def classifySpeciesBatch(self, batch):\n",
    "        detection_ids = batch[\"detection_ids\"]\n",
    "        images = batch[\"imagesInBatch\"]\n",
    "\n",
    "        # Create fastai test dataloader\n",
    "        test_dl = self.speciesLearner.dls.test_dl(images)\n",
    "\n",
    "        # Inference without progress bar or logging\n",
    "        # with self.speciesLearner.no_bar(), self.speciesLearner.no_logging():\n",
    "        preds, _ = self.speciesLearner.get_preds(dl=test_dl)\n",
    "        \n",
    "        # Get predictions classes and confidence\n",
    "        prds, cnfs = self.get_pred_conf(preds)\n",
    "\n",
    "        results = []\n",
    "        for idx, (prd, cnf) in enumerate(zip(prds, cnfs)):\n",
    "            if self.output_type=='species':\n",
    "                results.append({\n",
    "                    \"id\": detection_ids[idx],\n",
    "                    \"label\": self.id2name[prd[0]],\n",
    "                    \"labelId\": prd[0],\n",
    "                    \"confidence_value\": cnf[0]\n",
    "                })\n",
    "            elif self.output_type=='best':\n",
    "                i=0 # Index of when the cnf is above 0.5\n",
    "                while i < len(cnf) and cnf[i] < self.th: i += 1\n",
    "                if i == len(cnf): # No prediction, outputs highest level\n",
    "                    results.append({\n",
    "                        \"id\": detection_ids[idx],\n",
    "                        \"label\": self.id2name[prd[-1]],\n",
    "                        \"labelId\": prd[-1],\n",
    "                        \"confidence_value\": cnf[-1]\n",
    "                    })\n",
    "                else:\n",
    "                    results.append({\n",
    "                        \"id\": detection_ids[idx],\n",
    "                        \"label\": self.id2name[prd[i]],\n",
    "                        \"labelId\": prd[i],\n",
    "                        \"confidence_value\": cnf[i]\n",
    "                    })\n",
    "            elif self.output_type=='all':\n",
    "                results.append({\n",
    "                    \"id\": detection_ids[idx],\n",
    "                    \"label\": [self.id2name[p] for p in prd],\n",
    "                    \"labelId\": prd,\n",
    "                    \"confidence_value\": cnf\n",
    "                })\n",
    "            else:\n",
    "                raise NotImplementedError(\"Choose a valid output type.\")\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920f64c3-87d3-4cae-8b12-14c68c2966a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = Path(\"/home/george/codes/lepinet/data/flemming_ucloud/images\")\n",
    "img_filenames = list(img_dir.glob('*/*.jpg'))\n",
    "img_filenames[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c824099-6f42-4c31-81bc-f7f76829330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=FastaiSpeciesClassifier(speciesModelPath=\"/home/george/codes/lepinet/data/lepi/models/00_eulepi.pkl\", th=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a1bcbe-9036-4060-85da-fa949c397de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.classifySpeciesBatch({\"detection_ids\":list(range(len(img_filenames))),\"imagesInBatch\":img_filenames})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78ede5b-ad5b-41b7-bfb0-e297d217778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_id=[]\n",
    "filename=[]\n",
    "level=[]\n",
    "label=[]\n",
    "prediction=[]\n",
    "confidence=[]\n",
    "threshold=[] \n",
    "for i, f in enumerate(img_filenames):\n",
    "    instance_id += [i]\n",
    "    filename += [f]\n",
    "    level += [0]\n",
    "    label += [f.parent.name]\n",
    "    prediction += [str(preds[i]['labelId'])]\n",
    "    confidence += [float(preds[i]['confidence_value'])]\n",
    "    threshold += [0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd48ae6-7c01-4f37-94d4-d83979723718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'instance_id':instance_id,\n",
    "    'filename':filename,\n",
    "    'level':level,\n",
    "    'label':label,\n",
    "    'prediction':prediction,\n",
    "    'confidence':confidence,\n",
    "    'threshold':threshold})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08cdc2-ba3b-43a7-91b5-6cab9c041b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45c48d-5843-4303-8868-fbcaa0d7b12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/george/codes/lepinet/data/flemming_ucloud/old_fastai/fastai.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccbc3ef-2f3e-4ec5-bdfc-99f1d9ead992",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
